#!/usr/bin/env python


def process(input_info, selected_hits_angle, output_pairs_dir):
    layer_pair, ii = input_info
    out_name = os.path.join(output_pairs_dir, 'pair{:03d}.h5'.format(ii))
    if os.path.exists(out_name):
        return

    os.makedirs(output_pairs_dir, exist_ok=True)
    segments = list(utils_mldata.create_segments(selected_hits_angle, [layer_pair]))

    with pd.HDFStore(out_name) as store:
            store['data'] = segments[0]


if __name__ == "__main__":
    import os
    import argparse

    parser = argparse.ArgumentParser(description='make pairs for given evtid')
    add_arg = parser.add_argument
    add_arg('config', type=str, help='data configuration, configs/data.yaml')
    add_arg('evtid', type=int, help='event id')
    add_arg('--n-pids', type=int, help='how many particles should be used',
            default=-1)
    add_arg('--workers', type=int, help='workers', default=1)

    args = parser.parse_args()
    n_workers = args.workers

    import yaml
    assert(os.path.exists(args.config))
    with open(args.config) as f:
        config = yaml.load(f)

    data_dir = config['track_ml']['dir']
    black_list_dir = config['track_ml']['blacklist_dir']
    det_dir  = config['track_ml']['detector']
    base_dir = config['doublets_for_training']['base_dir']
    output_dir = os.path.join(base_dir, config['doublets_for_training']['all_pairs'])
    layers = config['doublets_for_graph']['layers']


    evtid = args.evtid
    n_pids = args.n_pids

    from heptrkx.preprocess import utils_mldata
    results = utils_mldata.read(data_dir, black_list_dir, evtid)
    if results is None:
        exit()
    else:
        hits, particles, truth, cells = results

    reco_pids = utils_mldata.reconstructable_pids(particles, truth)
    from heptrkx.nx_graph import utils_data
    import numpy as np
    import pandas as pd

    # noise included!
    hh = utils_data.merge_truth_info_to_hits(hits, particles, truth)
    unique_pids = np.unique(hh['particle_id'])
    print("event {} has {} particles {} reconstructable".format(evtid, unique_pids.shape, reco_pids.shape))

    if n_pids > 0:
        selected_pids = np.random.choice(unique_pids, size=n_pids)
        selected_hits = hh[hh.particle_id.isin(selected_pids)].assign(evtid=evtid)
    else:
        selected_hits = hh.assign(evtid=evtid)

    from heptrkx import layer_pairs, select_pair_layers
    sel_layer_id = select_pair_layers(layers)
    print("event {} uses {} Layers:".format(len(evtid, len(layers))))
    print("event {} Total {} Layer Pairs".format(evetid, len(sel_layer_id)))

    from heptrkx.nx_graph import transformation
    module_getter = utils_mldata.module_info(det_dir)

    from functools import partial

    local_angles = utils_mldata.cell_angles(selected_hits, module_getter, cells)
    selected_hits_angle = selected_hits.merge(local_angles, on='hit_id', how='left')

    pp_layers_info = [(layer_pairs[ii], ii) for ii in sel_layer_id]
    print("event {} uses {} Workers:".format(evtid, n_workers))

    import multiprocessing as mp
    with mp.Pool(processes=n_workers) as pool:
        pp_func=partial(process, selected_hits_angle=selected_hits_angle,
                        output_pairs_dir=os.path.join(output_dir, 'evt{}'.format(evtid)))
        pool.map(pp_func, pp_layers_info)
