#!/usr/bin/env python
"""
Calculate the fraction of particles that have at least one layer
in that more than one hit is recorded.
Only particles at specified _layers_ are considered.
"""
import os
import argparse
import glob
import re
import multiprocessing as mp
from functools import partial

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from heptrkx import load_yaml, select_pair_layers
from heptrkx.preprocess import utils_mldata
from heptrkx.nx_graph import utils_data

def fraction_of_duplicated_hits(evtid, config_name):
    config = load_yaml(config_name)
    evt_dir = config['track_ml']['dir']

    hits, particles, truth, cells = utils_mldata.read(evt_dir, evtid)
    hits = utils_data.merge_truth_info_to_hits(hits, particles, truth)
    layers = config['doublets_from_cuts']['layers']
    barrel_hits = hits[hits.layer.isin(layers)].assign(evtid=evtid)
    sel_layer_id = select_pair_layers(layers)

    # remove noise hits
    barrel_hits = barrel_hits[barrel_hits.particle_id > 0]


    sel = barrel_hits.groupby("particle_id")['layer'].apply(
        lambda x: len(x) - np.unique(x).shape[0]
    ).values
    return sel

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='make doublets using cut-based methods')
    add_arg = parser.add_argument
    add_arg('config', type=str, help='data configuration, configs/data.yaml')
    add_arg('--workers', type=int, help='workers', default=1)

    args = parser.parse_args()
    config_dir = args.config
    n_workers = args.workers

    config = load_yaml(config_dir)
    evt_dir = config['track_ml']['dir']
    all_files = glob.glob(os.path.join(evt_dir, '*hits*'))
    evtids = np.sort([int(
        re.search('event([0-9]*)', os.path.basename(x).split('-')[0]).group(1))
        for x in all_files])
    n_events = len(evtids)
    print("Total events: {}".format(n_events))

    with mp.Pool(processes=n_workers) as pool:
        pp_func = partial(fraction_of_duplicated_hits, config_name=config_dir)
        fraction_list = pool.map(pp_func, evtids)

        diff = np.concatenate(fraction_list, axis=None)
        plt.hist(diff, bins=11, range=(-0.5, 10.5), density=True)
        plt.xlabel("number of duplicated hits")
        plt.savefig("duplicated_hits.pdf")
