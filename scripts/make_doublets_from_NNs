#!/usr/bin/env python
"""
Use **make_pairs_for_training_segments** to make all pairs for the event,
then use **select_pairs** to select promising pairs (can run on GPU)
*  srun -n 10 make_doublets_from_NNs configs/data_5000evts.yaml
"""
import numpy as np
import pandas as pd
import yaml

from heptrkx import list_from_str

def process(evtid, config_dir):
    with open(config_dir) as f:
            config = yaml.load(f)

    mk_cfg = config['doublets_for_graph']
    threshold_file = os.path.expandvars(mk_cfg['threshold'])
    layers = mk_cfg['layers']

    df_threshold = pd.read_csv(threshold_file, sep=' ', header=None,
                               names=["idx", "in", "out", "cut", "eff", "purity", "n_true", "n_fake"])

    cmd_raw_pairs = ['make_pairs_for_training_segments', config_dir, str(evtid)]
    ck_code = subprocess.call(cmd_raw_pairs)
    if ck_code != 0:
        return

    from heptrkx import layer_pairs, select_pair_layers
    sel_layer_id = select_pair_layers(layers)

    for ii in sel_layer_id:
        layer_pair = layer_pairs[ii]
        try:
            cmd_sel_pairs =['select_pairs', config_dir, str(ii),
                            str(df_threshold[df_threshold.idx == ii]['cut'].values[0]),
                           str(evtid)]
            #print(" ".join(cmd_sel_pairs))
        except IndexError:
            print("pair {}-{}-{} is missing MODEL".format(ii, *layer_pair))
        ck_code = subprocess.call(cmd_sel_pairs)
        if ck_code != 0:
            return
        #print("pair selection:", ck_code)

if __name__ == "__main__":
    import os
    import argparse
    import subprocess

    parser = argparse.ArgumentParser(description='Keras train pairs for each layer-pairs')
    add_arg = parser.add_argument
    add_arg('config', type=str, help='data configuration, configs/data.yaml')
    add_arg('--workers', type=int, help='workers', default=1)

    args = parser.parse_args()
    config_dir = args.config
    n_workers = args.workers

    try:
        from mpi4py import MPI
        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()
        print("World size:", size, ", rank:", rank)
        use_mpi = True
    except ImportError:
        rank = 0
        size = 1
        use_mpi = False



    if rank == 0:
        assert(os.path.exists(config_dir))
        with open(config_dir) as f:
            config = yaml.load(f)

        mk_cfg = config['doublets_for_graph']
        evtids = mk_cfg['evtid']
        output_dir = os.path.expandvars(mk_cfg['selected'])
        os.makedirs(output_dir, exist_ok=True)
        if type(evtids) is str:
            evtids = list_from_str(evtids)
        else:
            evtids = [evtids]

        ## split evtids based on the world-size
        evtids = [x.tolist() for x in np.array_split(evtids, size)]
    else:
        evtids = None

    if use_mpi:
        comm.Barrier()
        evtids = comm.scatter(evtids, root=0)
    else:
        evtids = evtids[0]

    import multiprocessing as mp
    from functools import partial

    print("rank({}) {} workers:".format(rank, n_workers))
    print("rank({}) {} events:".format(rank, len(evtids)))

    with  mp.Pool(processes=n_workers) as pool:
        pp_func = partial(process, config_dir=config_dir)
        pool.map(pp_func, evtids)
